{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will start working with the Fake News Challenge dataset (https://github.com/FakeNewsChallenge/fnc-1). By the end of today, we hope you will be comfortable:\n",
    "1. Importing and exporting data from a Jupyter notebook\n",
    "2. Examining the structure of the dataset (how many rows and columns are in the dataset? What does each row and column represent?)\n",
    "3. With the goal of the Fake News Challenge. How good are you at identifying misleading headlines?  Do you think you can beat an AI?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytime you see ``______ # TODO: FILL IN HERE.`` in the code, you should replace the ``______`` with your own code.\n",
    "\n",
    "As always, ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import the packages we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Adjust settings so that we can fully see the dataset below\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://github.com/FakeNewsChallenge/fnc-1 and download the following files:\n",
    "    - train_stances.csv\n",
    "    - train_bodies.csv\n",
    "\n",
    "These files contain the data for the Fake News Challenge in the \"csv\" format. \"csv\" stands for \"comma-separate values\". We'll use this information later, when we tell the program how to load this data.\n",
    "\n",
    "PRO TIP: Make sure that the downloaded datasets and this jupyter notebook are in the same directory (folder), else you will have problems later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Understand what the data contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start looking at the data, we should understand what it contains and where it comes from.\n",
    "\n",
    "Go to http://www.fakenewschallenge.org/ and read up to, and including, the \"DATA\" section. Try to answer the following questions:\n",
    "\n",
    "    - What information do these .csv files contain?\n",
    "    - What is the classification goal posed by the Fake News Challenge?\n",
    "    - How was this data collected?\n",
    "    \n",
    "Discuss your answers with your neighbor or an instructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following code to load the data you downloaded into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stances = pd.read_csv(\"train_stances.csv\", encoding = \"utf-8\")\n",
    "train_bodies = pd.____(\"train_bodies.csv\", encoding = \"utf-8\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Look at the layout of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.columns`` parameter of a DataFrame tells us the name of the columns. Run the following cells to examine the column names of the DataFrames we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each dataset contains the column 'Body ID'. We will use this column later in order to match the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at the columns of the dataset, let's look at the rows. How many rows are in each dataset? We can use the ``.shape`` parameter to tell us about the number of rows in each dataset. Can you guess what the second number, returned by ``.shape``, corresponds to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of rows in ``train_stances`` is different to the number of rows in ``train_bodies``.  Why is this? How many unique entries are there for the ``Body ID`` variable in each dataset? We can use the ``pd.unique`` function to figure this out, and we can use ``[]`` (square parentheses) to isolate a single column in each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(train_stances['Body ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(train_bodies['Body ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! While the ``train_bodies`` dataset has one row for each value of the ``Body ID`` variable, there are multiple rows in ``train_stances`` corresponding to a single value of ``Body ID``.  Let's look at examples in each dataset corresponding to a value of 0 for the ``Body ID``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect there to be one row of the train_bodies dataset returned here:\n",
    "train_bodies[train_bodies['Body ID'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Let's check that there is exactly one row in train_bodies corresponding to Body ID = 0 by using the .shape parameter \n",
    "# discussed before:\n",
    "train_bodies[train_bodies['Body ID'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect there to be multiple rows of the train_stances dataset returned here: (Note: the .head() function \n",
    "# really useful for returning just a few rows)\n",
    "train_stances[train_stances['Body ID'] == 0].____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the shape parameter once more to check:\n",
    "train_stances[train_stances['Body ID'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the ``train_stances`` dataset contains multiple headlines corresponding to each article in ``train_bodies``, and our task is to train an AI to identify the correct headline associated with each article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Re-organize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we loaded contains all the information we need, but it puts different pieces of information about the same article in different DataFrames. To make the data easier to work with, we'd like to put the information about each article in one DataFrame.\n",
    "\n",
    "This function reads a dataset into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_bodies, train_stances, on='Body ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the shape of the newly created dataset:\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also look at the first few rows of this merged dataset:\n",
    "train_data.____()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exporting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created an amalgamated dataset, we'd like to export this, so that we can use it in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\", index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Extra challenge\" sections are a more unguided exploration into the concepts we've discussed. You'll notice less scaffolding for the code -- try implementing these concepts from scratch, and feel free to ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try looking at some other information about the data. Try to answer the following questions (and any others you think would be useful) -- feel free to look things up online along the way.\n",
    "\n",
    "    - How many examples are there for each stance? (For instance, how many \"unrelated\" examples are there?).\n",
    "        - Are each of the stances equally represented?\n",
    "    - In general, how long are the headings and article bodies?\n",
    "        - Does this differ for different stances?\n",
    "        - How much do these counts vary between different examples?\n",
    "    - When you read the article and headline and try to decide whether the headline agrees, disagrees, discusses the content of the article or is irrelevant, what factors do you consider?  How can we code these up so that a computer can gain our intuition and perform this classification by itself?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
