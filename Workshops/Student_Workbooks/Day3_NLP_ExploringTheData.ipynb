{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring The Data: Fake News Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's project session, we are going to think more about the Fake News Challenge dataset (https://github.com/FakeNewsChallenge/fnc-1) and the task of classifying the stance of the body text relative to the claim made in the headline into one of four categories:\n",
    "1. Agrees: The body text agrees with the headline.\n",
    "2. Disagrees: The body text disagrees with the headline.\n",
    "3. Discusses: The body text discuss the same topic as the headline, but does not take a position\n",
    "4. Unrelated: The body text discusses a different topic than the headline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will:\n",
    "1. Look at the distribution of examples across stance classes\n",
    "2. Think about the rules we, as humans, use to perform the article-headline classification challenge. We will then explore if these rules enable the computer to separate out the different stance classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytime you see ``______ # TODO: FILL IN HERE.`` in the code, you should replace the ``______`` with your own code.\n",
    "\n",
    "As always, ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the training data if you don't already have it\n",
    "def merge_data(stances_filename, bodies_filename, merged_filename):\n",
    "    stances = pd.read_csv(stances_filename, encoding = \"utf-8\")\n",
    "    bodies = pd.read_csv(bodies_filename, encoding = \"utf-8\")\n",
    "    data = pd.merge(bodies, stances, on='Body ID')\n",
    "    data.to_csv(merged_filename, index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the dataset we created yesterday (and we will create it if it doesn't already exist; you may need to \n",
    "# adjust the file path if python cannot find the 'train_stances.csv' and 'train_bodies.csv' files):\n",
    "if os.path.isfile('train_data.csv') == False:\n",
    "    merge_data(\"../train_stances.csv\", \"../train_bodies.csv\", \"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the training data and separate out the training data according to the value of the Stance variable:\n",
    "train_data = pd.read_csv(\"train_data.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: what do these datasets look like? Use a function that you encountered yesterday to display the first few \n",
    "# rows of the training dataset:\n",
    "train_data._____() # TODO: FILL IN HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stance variable distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the goal of this challenge is to teach the computer to 'read' in article/headline pairs and predict the associated value of the Stance variable (UNRELATED/DISCUSS/AGREE/DISAGREE).  First, we should look at the number of examples that we have for each value of the stance variable that we can use for teaching the computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of stance variables in the dataset:\n",
    "train_data.Stance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And as a proportion of the rows in the dataset: (use an attribute of train_data that you learned about yesterday to\n",
    "# divide the count values by the number of rows in the dataset)\n",
    "train_data.Stance.value_counts()/train_data.____[0] # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have a very uneven dataset, with many more examples of UNRELATED article/headline pairs compared to DISCUSS/AGREE/DISAGREE article/headline pairs. We will discuss the consequences of this uneven distribution later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploring the data - Can we find features that are different across stance groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we are going to work with a reduced subset of the training dataset, which has an equal number of examples from each Stance category. We will return to working with the full dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. Randomly sample 100 examples from each stance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrelated = train_data[train_data['Stance'] == 'unrelated'].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discuss = train_data[train_data['Stance'] == 'discuss'].sample(_____) # TODO: FILL IN HERE\n",
    "agree = train_data[train_data['Stance'] == 'agree']._____(_____) # TODO: FILL IN HERE\n",
    "disagree = train_data[train_data['Stance'] == _____].sample(100) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that each class has one hundred samples:\n",
    "unrelated._____[0] # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. What distinguishes each class? \n",
    "When headlines and articles are 'unrelated', is the proportion of words from the article contained in the headline different to that for other stance classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the proportion of words that are contained in a headline that are also contained in an article for \n",
    "# a headline-article example.  Let's create a function that reads in an example (single row in any of the dataframes we \n",
    "# created above) and returns the proportion of the headline that is contained in the article:\n",
    "def find_headline_in_article_proportion(example):\n",
    "    # Separate out all of the individual words in headline:\n",
    "    headline_words = str.split(example['Headline'])\n",
    "    # Separate out all of the individual words in the article:\n",
    "    article_words = str.split(example['articleBody'])\n",
    "    # Counter to count the number of words in the headline that are contained in the article\n",
    "    counter = 0 \n",
    "    # Now iterate through each of the words in the headline and check if the word also exists in the article\n",
    "    for word in headline_words:\n",
    "        if word in article_words:\n",
    "            # If the word in the headline is contained in the article, add 1 to the counter\n",
    "            counter += 1\n",
    "    # Since the length of each headline is different, what we really want to compare across examples is the proportion \n",
    "    # of the headline that is contained in the article \n",
    "    proportion = counter/len(headline_words)\n",
    "    return proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply the function to all examples in each of the four dataframes we created above.\n",
    "# We will save the results to a list:\n",
    "proportions_unrelated = [] # Save results to this list\n",
    "for i in range(unrelated.shape[0]):\n",
    "    # Extract example\n",
    "    this_example = unrelated.iloc[i]\n",
    "    # Save result of calling find_headline_in_article_proportion() on example to proportions_unrelated list\n",
    "    proportions_unrelated.append(find_headline_in_article_proportion(this_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same for each of the other stance classes:\n",
    "# discuss class\n",
    "proportions_discuss= [] \n",
    "for i in range(discuss.shape[0]):\n",
    "    this_example = discuss.iloc[____] # TODO: FILL IN HERE\n",
    "    proportions_discuss.append(find_headline_in_article_proportion(_____)) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agree class\n",
    "proportions_agree= [] \n",
    "for i in range(agree.____): # TODO: FILL IN HERE\n",
    "    this_example = agree.iloc[i]\n",
    "    proportions_agree.append(find_headline_in_article_proportion(this_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disagree class\n",
    "proportions_______= [] # TODO: FILL IN HERE\n",
    "for i in range(disagree.shape[0]):\n",
    "    this_example = disagree.iloc[i]\n",
    "    proportions_disagree.append(_______(this_example)) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3c. Calculate mean proportion for each stance class.\n",
    "What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrelated\n",
    "np.mean(proportions_unrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agree\n",
    "np.mean(________agree) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss\n",
    "_____.mean(proportions_discuss) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disagree\n",
    "np._____(proportions_disagree) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3d. Visualize the differences in proportions across stance classes\n",
    "We will create a boxplot to show the differences in proportions across stance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = [proportions_unrelated, proportions_agree, proportions_disagree, ___________] # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure instance\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Create the boxplot\n",
    "bp = ax.boxplot(data_to_plot)\n",
    "# Set the xaxis tick marks\n",
    "ax.set_xticklabels(['Unrelated', 'Agree', 'Disagree', 'Discuss'])\n",
    "# Set the yaxis label\n",
    "ax.set_ylabel('Proportion headline in article')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice from the boxplot? From the boxplot, could you come up with a rule for the computer to use in order to classify article-headline examples as UNRELATED/AGREE/DISAGREE/DISCUSS? What about if the challenge was only to classify pairs as either UNRELATED or RELATED (with RELATED = AGREE + DISAGREE + DISCUSS)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Extra challenge\" sections are a more unguided exploration into the concepts we've discussed. You'll notice less scaffolding for the code -- try implementing these concepts from scratch, and feel free to ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining your boxplot's results and coming up with a rule for the computer to use in order to classify article-headline pairs as UNRELATED/RELATED, test out this rule on some examples from the training dataset. Is your rule able to correctly predict the true value of Stance for each example?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
