{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll create some rule-based classifiers. In this workbook, we'll practice working with Python and the FNC data, and create a simple FNC predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytime you see ``______ # TODO: FILL IN HERE.`` in the code, you should replace the ``______`` with your own code.\n",
    "\n",
    "As always, ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import the packages we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have ``train_data.csv`` and ``test_data.csv`` saved, run the following code to construct and save csvs of the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_data(stances_filename, bodies_filename, merged_filename):\n",
    "    stances = pd.read_csv(stances_filename, encoding = \"utf-8\")\n",
    "    bodies = pd.read_csv(bodies_filename, encoding = \"utf-8\")\n",
    "    data = pd.merge(bodies, stances, on='Body ID')\n",
    "    data.to_csv(merged_filename, index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_data(\"train_stances.csv\", \"train_bodies.csv\", \"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_data(\"competition_test_stances.csv\", \"competition_test_bodies.csv\", \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Separate the dataset based on stance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in and run the following cells to separate the train and test sets based on their stance. This will help us generate and test our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\", encoding = \"utf-8\")\n",
    "unrelated_train = train_data[train_data['Stance'] == ____]\n",
    "discuss_train = train_data[train_data['Stance'] == ____]\n",
    "agree_train = train_data[train_data['Stance'] == ____]\n",
    "disagree_train = train_data[train_data['Stance'] == ____]\n",
    "\n",
    "test_data = pd.read_csv(\"test_data.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a classifer based on shared words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first classifier will be based on the percentage of headline words that appear in the article. We'll find the average percentage for each stance. When our classifier gets a headline-article pair, it'll find the percentage of headline words in the article and then predict the stance with the closest average percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, try to write out the steps of this classifier, and the components we'll need to write to create the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. Write a function that finds the proportion of headline words in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_headline_in_article_proportion(example):\n",
    "    headline_words = str.split(example[____])\n",
    "    article_words = str.split(example[____])\n",
    "    counter = 0\n",
    "    for word in headline_words:\n",
    "        if word in ____:\n",
    "            counter += 1\n",
    "    proportion = ____/len(____)\n",
    "    return proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Find the average proportion for each stance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_proportions(unrelated, discuss, agree, disagree):\n",
    "    proportions_unrelated = []\n",
    "    for i in range(unrelated.shape[0]):\n",
    "        this_example = ____.iloc[i]\n",
    "        proportions_unrelated.append(____(this_example))\n",
    "    proportions_related = []\n",
    "    proportions_discuss= []\n",
    "    for i in range(discuss.shape[0]):\n",
    "        this_example = ____.iloc[i]\n",
    "        proportions_discuss.append(____(this_example))\n",
    "        proportions_related.append(____(this_example))\n",
    "    proportions_agree= []\n",
    "    for i in range(agree.shape[0]):\n",
    "        this_example = ____.iloc[i]\n",
    "        proportions_agree.append(____(this_example))\n",
    "        proportions_related.append(____(this_example))\n",
    "    proportions_disagree= []\n",
    "    for i in range(disagree.shape[0]):\n",
    "        this_example = ____.iloc[i]\n",
    "        proportions_disagree.append(____(this_example))\n",
    "        proportions_related.append(____(this_example))\n",
    "    return {\"unrelated\":np.mean(proportions_unrelated), \"discuss\":np.mean(proportions_discuss), \"agree\":np.mean(proportions_agree), \"disagree\":np.mean(proportions_disagree), \"related\":np.mean(proportions_related)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportions = compute_proportions(____, ____, ____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3c. Write a prediction function based on the closest average proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(example, proportions):\n",
    "    proportions_stances = list(proportions.keys())\n",
    "    proportion = ____(example)\n",
    "    predicted_stance = proportions_stances[np.argmin(np.abs(np.array(list(proportions.values())) - proportion))]\n",
    "    return predicted_stance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a.  Write a function that runs and evaluates predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_predictions(test_data, proportions):\n",
    "    stance_counts = {\"unrelated\":0, \"discuss\":0, \"agree\":0, \"disagree\":0}\n",
    "    stance_correct_counts = {\"unrelated\":0, \"discuss\":0, \"agree\":0, \"disagree\":0}\n",
    "    for i in range(test_data.shape[0]):\n",
    "        example = test_data.iloc[i]\n",
    "        predicted_stance = ____(example, proportions)\n",
    "        actual_stance = example[____]\n",
    "        ____[____] += 1\n",
    "        if predicted_stance == actual_stance:\n",
    "            ____[____] += 1\n",
    "    return {\"unrelated\":____[\"unrelated\"]/____[\"unrelated\"], \"discuss\":____[\"discuss\"]/____[\"discuss\"], \"agree\":____[\"agree\"]/____[\"agree\"], \"disagree\":____[\"disagree\"]/____[\"disagree\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Test the classifier and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_percentages = ____(test_data, proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agree': 0.4703100367840252,\n",
       " 'disagree': 0.21377331420373027,\n",
       " 'discuss': 0.0035842293906810036,\n",
       " 'unrelated': 0.9000490489944956}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What categories does the predictor do well on, and what does the predictor do less well on? Why do you think this is? (hint: take a look at the average proportion of in-article headline words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the number of examples in each category, and compute the overall classification accuracy. Is this higher or lower than you would have expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unrelated_test = test_data[test_data['____'] == '____']\n",
    "discuss_test = test_data[test_data['____'] == '____']\n",
    "agree_test = test_data[test_data['____'] == '____']\n",
    "disagree_test = test_data[test_data['____'] == '____']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall_accuracy = (correct_percentages['____'] * agree_test.shape[0] \\\n",
    "                    + correct_percentages['____'] * discuss_test.shape[0] \\\n",
    "                    + correct_percentages['____'] * disagree_test.shape[0] \\\n",
    "                    + correct_percentages['____'] * unrelated_test.shape[0]) \\\n",
    "                    / ____.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691575178058474"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Extra challenge\" sections are a more unguided exploration into the concepts we've discussed. You'll notice less scaffolding for the code -- try implementing these concepts from scratch, and feel free to ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 1. Two-way classification.\n",
    "\n",
    "Try adapting our code for four-way classification (between 'unrelated', 'agree', 'disagree', and 'discuss') for two-way classification (between 'unrelated' and 'related'). To do this, we'll group 'agree', 'disagree', and 'discuss' examples into a single 'related' category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2. Experiment with more statistics.\n",
    "In today's classifier, we compared the proportion of in-article headline words to the mean of each stance category. Experment with some different statistics. Some ideas:\n",
    "- Use the median instaed of the mean for each stance.\n",
    "- The 'Jaccard index' between two bodies of text, A and B, is (number of words shared by A and B)/(number of words in either A or B). Try using the Jaccard index instead of the proportion of in-article headline words. (hint: look up the functions set(), intersection(), and union())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
