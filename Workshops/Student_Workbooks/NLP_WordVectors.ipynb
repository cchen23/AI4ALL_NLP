{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytime you see ``______ # TODO: FILL IN HERE.`` in the code, you should replace the ``______`` with your own code.\n",
    "\n",
    "As always, ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Word Vectors\n",
    "Let's start by working with pre-trained word vectors. These are word representations that have been created by other people, which we can download and use for our applications.\n",
    "\n",
    "We'll work with vectors trained using the Word2Vec model. Other people have already created these vectors, which are available to download online. Don't worry about the specific methods used to create these vectors for this class, but if you're interested in learning more feel free to ask one of the instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  0. Import packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import the packages we need in the rest of this notebook.\n",
    "\n",
    "As a reminder, press ctrl-enter to run a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download pre-trained word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a. Download the data online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the word vectors, go to this link: https://nlp.stanford.edu/projects/glove/\n",
    "and search for \"glove.6B.zip\".\n",
    "\n",
    "Download this file, and save it in the same folder as this notebook.\n",
    "\n",
    "Then extract the files contained in the .zip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b. Load the word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided the \"read_embeddings\" function, which takes in the name of one of the embedding files and reads it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two cells to create the ``read_embeddings`` function and load a set of embeddings into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_embeddings(filename):\n",
    "    word_embeddings = pd.read_table(filename, header=None, sep=\" \", index_col=0, quoting=3)\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_file = 'glove.6B/glove.6B.200d.txt'\n",
    "embeddings_df = read_embeddings(embeddings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c. Look at some examples of word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To manually examine the first few rows of a DataFrame, we can use the ``.head()`` function of the DataFrame.\n",
    "\n",
    "In this case, we named the DataFrame ``embeddings_df``, so we run ``embeddings_df.head()`` to view the first few rows.\n",
    "\n",
    "Run the following cell to see the first few embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can view the embedding of a specific word using the code\n",
    "\n",
    "``embeddings_df.loc[word]``\n",
    "\n",
    "Try it with a few words of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_word = ______ # TODO: FILL IN HERE.\n",
    "embeddings_df.loc[selected_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a function to compute cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write a function to compute the cosine similarity between two words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a: Fill in the function definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following function; feel free to discuss with your neighbors and look back to today's slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(word_a, word_b):\n",
    "    word_a_vector = embeddings_df.loc[word_a]\n",
    "    word_b_vector = _____ # TODO: FILL IN HERE\n",
    "    word_a_vectornorm = np.linalg.norm(word_a_vector)\n",
    "    word_b_vectornorm = ____ # TODO: FILL IN HERE\n",
    "    a_dot_b = np.dot(word_a_vector, ____ ) # TODO: FILL IN HERE\n",
    "    cosine_similarity = # TODO: FILL IN HERE\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b: Test your cosine similarity function with different words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out your function with some sample words, and write some examples of cosine similarities between words you tried. Do the results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_a = _____ # TODO: FILL IN HERE\n",
    "word_b = _____ # TODO: FILL IN HERE\n",
    "similarity = compute_cosine_similarity(word_a, word_b)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a function to find the closest words to a selected word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've written a function to compute the cosine similarity between two words, it's time to try solving our own analogies!\n",
    "\n",
    "As a recap, we can solve analogies using the following translation from words to math:\n",
    "\n",
    "$A\\:is\\:to\\:B\\:as\\:C\\:is\\:to\\:D \\leftrightarrow A-B\\approx C-D \\leftrightarrow C+B-A\\approx D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, try filling in the following function to solve an analogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predicted_index_vectorized(v1, v2, v3, embeddings_matrix):\n",
    "    embeddings_index = embeddings_df.index\n",
    "    v1_index = embeddings_index.get_loc(v1)\n",
    "    v2_index = embeddings_index.get_loc(v2)\n",
    "    v3_index = embeddings_index.get_loc(v3)\n",
    "    v1 = embeddings_matrix[v1_index,:]\n",
    "    v2 = embeddings_matrix[v2_index,:]\n",
    "    v3 = embeddings_matrix[v3_index,:]\n",
    "    predicted_vec = (____ + ____ - ____).reshape(1, embeddings_df.shape[1]) # TODO: FILL IN HERE.\n",
    "    diffs = np.sum((embeddings_matrix - predicted_vec) ** 2, axis=1)\n",
    "    min_indices = diffs.argsort()[:4]\n",
    "    for i in range(3):\n",
    "        min_index = min_indices[i]\n",
    "        if min_index != v1_index and min_index != v2_index and min_index != v3_index:\n",
    "            return(embeddings_index[min_index])\n",
    "    return embeddings_index[min_indices[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Try solving your own analogies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using your function to solve your own analogies.\n",
    "\n",
    "To start, here are some you might try:\n",
    "\n",
    "    \"boy\" is to \"girl\" as \"brother\" is to ?\n",
    "    \"uncle\" is to \"aunt\" as \"policewoman\" is to ?\n",
    "    \"occasional\" is to \"occasionally\" as \"lucky\" is to ?\n",
    "    \"jumping\" is to \"jumped\" as \"flying\" is to ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Extra challenge\" sections are a more unguided exploration into the concepts we've discussed. You'll notice less scaffolding for the code -- try implementing these concepts from scratch, and feel free to ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your Own Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've worked with previously trained word vectors, try constructing your own word vectors using the methods we discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create vectors using co-occurrence counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a: Write out the pseudocode (the logical steps) for constructing word vectors using co-occurrence counts. What information will you need to keep track of? How can you find this information? How can you turn this information into word vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b: Write some code to compute word vectors using co-occurrence counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create vectors using PPMI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a: Write out the pseudocode for constructing vectors using PPMI. Are there any steps you can re-use from part 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b: Write some code to compute word vectors using PPMI. Can you re-use any code from part 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualize projections of these embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These embeddings are useful mathematically, but they have a lot of dimensions, which makes it hard to visualize them.\n",
    "\n",
    "For easier visualization, we can project them onto fewer dimensions. Using projection, we can map something in many dimensions (in the case of these word vectors, 200 dimensions) into fewer dimensions (in particular, two dimensions are easy to visualize).\n",
    "\n",
    "Projecting onto fewer dimensions makes us lose some information. For instance, imagine that we have a full-color picture and map it to a black-and-white picture -- the new picture might be easier to represent, but we lose some information in the process.\n",
    "\n",
    "Using certain techniques, we can make a lower-dimensional projection that keeps as much information as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = X.mean(0)\n",
    "C = np.cov(X - mu, rowvar=False)\n",
    "d, u = np.linalg.eigh(C)\n",
    "U = u.T[::-1]\n",
    "Z = np.dot(X - mu, U[:2].T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
