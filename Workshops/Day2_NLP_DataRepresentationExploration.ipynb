{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anytime you see ``______ # TODO: FILL IN HERE.`` in the code, you should replace the ``______`` with your own code.\n",
    "\n",
    "As always, ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll explore the Fake News Challenge dataset using some of the techniques we talked about in the earlier slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import the packages we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to https://github.com/FakeNewsChallenge/fnc-1 and download the following files:\n",
    "    - train_stances.csv\n",
    "    - train_bodies.csv\n",
    "    - competition_test_stances.csv\n",
    "    - competition_test_bodies.csv\n",
    "\n",
    "These files contain the data for the Fake News Challenge in the \"csv\" format. \"csv\" stands for \"comma-separate values\". We'll use this information later, when we tell the program how to load this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Understand what the data contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start looking at the data, we should understand what it contains and where it comes from.\n",
    "\n",
    "Go to http://www.fakenewschallenge.org/ and read up to, and including, the \"DATA\" section. Try to answer the following questions:\n",
    "\n",
    "    - What information do these .csv files contain?\n",
    "    - What is the classification goal posed by the Fake News Challenge?\n",
    "    - How was this data collected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following code to load the data you downloaded into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stances = pd.read_csv(\"train_stances.csv\")\n",
    "train_bodies = pd.read_csv(______) # TODO: FILL IN HERE\n",
    "test_stances = pd.read_csv(______) # TODO: FILL IN HERE\n",
    "test_bodies = pd.read_csv(______) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Look at the layout of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.columns`` parameter of a DataFrame tells us the name of the columns. Run the following cells to examine the column names of the DataFrames we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stances.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bodies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stances.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bodies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Re-organize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we loaded contains all the information we need, but it puts different pieces information about the same article in different DataFrames. To make the data easier to work with, we'd like to put the information about each article in one DataFrame.\n",
    "\n",
    "This function reads a dataset into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = read(\"train_stances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_merged_data(bodies_filename, stances_filename):\n",
    "    with open(stances_filename, \"r\", encoding='utf-8') as table:\n",
    "            reader = csv.reader(table)\n",
    "            stances_dict = {rows[1]:(rows[0], rows[2]) for rows in reader}\n",
    "\n",
    "    with open(bodies_filename, \"r\", encoding='utf-8') as table:\n",
    "            reader = csv.reader(table)\n",
    "            bodies_dict = {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "    merged_df = pd.DataFrame(columns=['heading','articleBody', 'stance'])\n",
    "\n",
    "    for key, value in stances_dict.items():\n",
    "        if key == 'Body ID':\n",
    "            continue\n",
    "        merged_df = merged_df.append({'heading':value[0], 'stance':value[1], 'articleBody':bodies_dict[key]}, ignore_index=True)\n",
    "    return merged_df\n",
    "def read(filename):\n",
    "    rows = []\n",
    "    with open(filename, \"r\", encoding='utf-8') as table:\n",
    "        reader = csv.reader(table)\n",
    "        mydict = {rows[1]:(rows[0], rows[2]) for rows in reader}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, create a single DataFrame for the train data and one for the test data. There's a lot of data, so this might take some time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = read_merged_data(____, ____) # TODO: FILL IN HERE # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_merged_data(____, ____) # TODO: FILL IN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Look at some statistics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``.shape`` attribute of a DataFrame gives us the shape of the DataFrame. Run the following cell to see the shapes of our newly created DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many train examples do we have? How many test examples do we have? What does the second number in the ``.shape`` output represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Manually examine some inputs and outputs from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try looking at some specific inputs and outputs from the dataset. Recall that the ``.head()`` function lets us look at the first few rows of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.____ # TODO: FILL IN HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.____ # TODO: FILL IN HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Extra challenge\" sections are a more unguided exploration into the concepts we've discussed. You'll notice less scaffolding for the code -- try implementing these concepts from scratch, and feel free to ask your neighbors or an instructor if you have any questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try looking at some other information about the data. Try to answer the following questions (and any others you think would be useful) -- feel free to look things up online along the way.\n",
    "\n",
    "    - How many examples are there for each stance? (For instance, how many \"unrelated\" examples are there?).\n",
    "        - Are each of the stances equally represented?\n",
    "        - Does this differ between the train and test sets?\n",
    "    - In general, how long are the headings and article bodies?\n",
    "        - Does this differ for different stances?\n",
    "        - How much do these counts vary between different examples?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
